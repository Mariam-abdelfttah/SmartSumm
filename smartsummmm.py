# -*- coding: utf-8 -*-
"""SmartSummmm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JO5mGlY8Daq0sJ95DyFnyc75Kl8aZqiF
"""

# تثبيت المكتبات المطلوبة مرة واحدة فقط
!pip install transformers datasets rouge-score sumy bs4 nltk

# حذف الكاش الخاص بـ Huggingface لتفادي المشاكل في التحميل أو التحديث
!rm -rf /root/.cache/huggingface

# استيراد NLTK وتنزيل بيانات punkt (مطلوبة للتقسيم إلى جمل)
import nltk
nltk.download('punkt')

import pandas as pd

# قراءة ملف CSV باسم "xsum.csv" في DataFrame
df = pd.read_csv("xsum.csv")

# اختيار أول 50 صف فقط لأغراض الاختبار أو العرض السريع
subset = df.head(50)

# عرض أول 5 صفوف من البيانات للتحقق من محتويات الملف

df.head()

from transformers import BartTokenizer, BartForConditionalGeneration

# هنا بنحدد اسم موديل BART اللي هنعمل عليه التلخيص
bart_model_name = "facebook/bart-large-xsum"

# بنجيب أداة تحويل الكلمات لنماذج رقمية (tokenizer) الخاصة بالموديل ده
bart_tokenizer = BartTokenizer.from_pretrained(bart_model_name)

# بنحمل الموديل نفسه اللي هيعمل التلخيص للنصوص
bart_model = BartForConditionalGeneration.from_pretrained(bart_model_name)

from tqdm import tqdm  # مكتبة لعرض شريط تقدم أثناء التكرار

bart_summaries = []  # قائمة لتخزين الملخصات اللي هيتولدوا

# بنلف على كل نص في العمود "input" من الـ subset، ونستخدم tqdm عشان نتابع التقدم
for text in tqdm(subset["input"].tolist(), desc="BART Summaries"):
    # بنحول النص إلى رموز رقمية مناسبة للموديل، مع تحديد طول أقصى 1024 كلمة ورمي الزيادة
    inputs = bart_tokenizer.encode(text, return_tensors="pt", max_length=1024, truncation=True)

    # بنستخدم الموديل لتوليد ملخص، مع إعدادات:
    # max_length: أقصى طول للملخص 60 كلمة
    # min_length: أقل طول للملخص 10 كلمات
    # length_penalty: يعاقب الملخصات القصيرة عشان نخليها أكثر معلوماتية
    # num_beams: عدد المسارات اللي بيتجربها الموديل (4 يعني بيبحث بشكل أعمق)
    # early_stopping: يوقف التوليد لما الملخص يكون مكتمل
    summary_ids = bart_model.generate(
        inputs,
        max_length=60,
        min_length=10,
        length_penalty=2.0,
        num_beams=4,
        early_stopping=True
    )

    # بنرجع الملخص نصي من الرموز الرقمية، ونتجاهل الرموز الخاصة بالموديل
    summary = bart_tokenizer.decode(summary_ids[0], skip_special_tokens=True)

    # بنضيف الملخص لقائمة الملخصات
    bart_summaries.append(summary)

# بنضيف عمود جديد بالملخصات في الـ DataFrame
subset["bart_summary"] = bart_summaries

from transformers import T5Tokenizer, T5ForConditionalGeneration

# هنا بنجيب أداة تحويل الكلام لأرقام (tokenizer) لموديل T5 العادي
t5_tokenizer = T5Tokenizer.from_pretrained("t5-base")

# وبنجيب موديل T5 نفسه اللي هيشتغل على التوليد (زي التلخيص أو الترجمة)
t5_model = T5ForConditionalGeneration.from_pretrained("t5-base")

t5_summaries = []  # هنا هنحفظ كل الملخصات اللي هنطلعها من موديل T5

# بندور على كل نص في العمود "input" من الـ subset، وشريط التقدم هيورينا الحالة
for text in tqdm(subset["input"].tolist(), desc="T5 Summaries"):
    # بنضيف كلمة "summarize:" قدام النص عشان الموديل يفهم انه التلخيص هو المطلوب
    input_text = "summarize: " + text

    # بنحول النص لأرقام عشان الموديل يفهمه، مع تحديد أقصى طول 512 كلمة
    inputs = t5_tokenizer.encode(input_text, return_tensors="pt", max_length=512, truncation=True)

    # بنطلب من الموديل يولد ملخص بالكلمات اللي عايزينها (بين 10 و 60 كلمة)
    summary_ids = t5_model.generate(
        inputs,
        max_length=60,
        min_length=10,
        length_penalty=2.0,
        num_beams=4,
        early_stopping=True
    )

    # بنرجع النص من الرموز الرقمية، وبنتجاهل الرموز الخاصة اللي مش محتاجينها
    summary = t5_tokenizer.decode(summary_ids[0], skip_special_tokens=True)

    # بنضيف الملخص للقائمة
    t5_summaries.append(summary)

# في الآخر بنضيف عمود جديد فيه الملخصات الناتجة لمجموعة البيانات
subset["t5_summary"] = t5_summaries

from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.text_rank import TextRankSummarizer
import nltk  # للتأكد من تحميل الموارد اللازمة

# تحميل المورد المطلوب لتحليل الجمل، اسمه الصحيح هو 'punkt' مش 'punkt_tab'
nltk.download('punkt')
# تحميل مورد NLTK الإضافي المطلوب بواسطة sumy للغة الإنجليزية
nltk.download('punkt_tab')

textrank_summaries = []  # قائمة لحفظ الملخصات

for text in tqdm(subset["input"].tolist(), desc="TextRank Summaries"):
    # بنحول النص لكائن يحلله sumy باستخدام Tokenizer للإنجليزي
    parser = PlaintextParser.from_string(text, Tokenizer("english"))

    # بنستخدم ملخص TextRank
    summarizer = TextRankSummarizer()

    # بنطلب 3 جمل كملخص للنص
    summary = summarizer(parser.document, 3)

    # بنحول الجمل ل string واحدة مفصولة بمسافات
    joined = " ".join(str(sentence) for sentence in summary)

    # بنضيف الملخص للقائمة
    textrank_summaries.append(joined)

# بنضيف عمود جديد بالملخصات في الـ DataFrame
subset["textrank_summary"] = textrank_summaries

from rouge_score import rouge_scorer

# بنحدد المقاييس اللي هنقيم بيها: rouge-1 (كلمات مفردة)، rouge-2 (كلمات زوجية)، rouge-L (أطول سلسلة متتابعة)
scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)

def compute_rouge(refs, gens):
    r1, r2, rL = [], [], []  # قوائم لتخزين نتائج كل مقياس
    for ref, gen in zip(refs, gens):
        scores = scorer.score(ref, gen)  # بنحسب المقاييس بين المرجع (ref) والنص المولد (gen)
        r1.append(scores["rouge1"].fmeasure)  # إضافة نتيجة rouge-1
        r2.append(scores["rouge2"].fmeasure)  # إضافة نتيجة rouge-2
        rL.append(scores["rougeL"].fmeasure)  # إضافة نتيجة rouge-L
    return r1, r2, rL  # نرجع كل النتائج

# حساب نتائج Rouge لكل نموذج مقارنة مع النصوص المرجعية في العمود "target"
bart_r1, bart_r2, bart_rL = compute_rouge(subset["target"], subset["bart_summary"])
t5_r1, t5_r2, t5_rL = compute_rouge(subset["target"], subset["t5_summary"])
txt_r1, txt_r2, txt_rL = compute_rouge(subset["target"], subset["textrank_summary"])

def print_rouge(name, r1, r2, rL):
    # بنطبع اسم النموذج
    print(f"\n{name} ROUGE Scores")
    # بنحسب المتوسط لكل مقياس ونطبع النتيجة بأربع أرقام عشرية
    print(f"ROUGE-1: {sum(r1)/len(r1):.4f}")
    print(f"ROUGE-2: {sum(r2)/len(r2):.4f}")
    print(f"ROUGE-L: {sum(rL)/len(rL):.4f}")

# عرض النتائج لكل موديل حسب المقاييس اللي حسبناها
print_rouge("BART", bart_r1, bart_r2, bart_rL)
print_rouge("T5", t5_r1, t5_r2, t5_rL)
print_rouge("TextRank", txt_r1, txt_r2, txt_rL)

import matplotlib.pyplot as plt

labels = ["ROUGE-1", "ROUGE-2", "ROUGE-L"]
x = range(len(labels))

plt.bar([i - 0.3 for i in x], [sum(bart_r1)/len(bart_r1), sum(bart_r2)/len(bart_r2), sum(bart_rL)/len(bart_rL)], width=0.3, label="BART")
plt.bar(x, [sum(t5_r1)/len(t5_r1), sum(t5_r2)/len(t5_r2), sum(t5_rL)/len(t5_rL)], width=0.3, label="T5")
plt.bar([i + 0.3 for i in x], [sum(txt_r1)/len(txt_r1), sum(txt_r2)/len(txt_r2), sum(txt_rL)/len(txt_rL)], width=0.3, label="TextRank")

plt.xticks(x, labels)
plt.ylabel("ROUGE F1 Score")
plt.title("Summarization Comparison on XSum (50 samples)")
plt.legend()
plt.show()

subset.to_csv("xsum_bart_t5_textrank_comparison.csv", index=False)
print("Saved to xsum_bart_t5_textrank_comparison.csv")