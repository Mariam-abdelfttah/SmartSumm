# ğŸ§¾ SmartSumm: Abstractive Summarization with Transformers and TextRank

<div align="center">
  <img src="https://img.shields.io/badge/Python-3.8%2B-blue?logo=python" alt="Python">
  <img src="https://img.shields.io/badge/License-MIT-green">
  <img src="https://img.shields.io/badge/Hugging%20Face-Transformers-yellow?logo=huggingface">
  <img src="https://img.shields.io/badge/Status-Active-success">
</div>

---

## ğŸš€ Project Overview

**SmartSumm** is a research project comparing the performance of state-of-the-art abstractive summarization models (**BART**, **T5**) with the traditional extractive method **TextRank**. Using the XSum news dataset, the project evaluates the accuracy and efficiency of modern models for automatic text summarization.

---

## ğŸ¯ Objective

Summarizing long content is crucial in domains such as news, medicine, and education. This project addresses the question:

> "Do Transformer-based models truly outperform traditional approaches for text summarization?"

---

## âœ¨ Features

- âš¡ï¸ Utilizes pre-trained models from Hugging Face: `facebook/bart-large-xsum`, `t5-base`
- ğŸ“° Summarizes 50 real news articles
- ğŸ“Š Compares performance using ROUGE scores
- ğŸ“ˆ Visualizes differences between models
- ğŸ—‚ï¸ Saves all results in a structured CSV file

---

## ğŸ› ï¸ Tech Stack

- Python 3.8+
- Hugging Face Transformers
- Datasets (XSum)
- Sumy, NLTK
- Matplotlib, pandas

---

## ğŸš¦ Quick Start

1. Make sure you have Python and Jupyter Notebook installed, or use Google Colab.
2. Install the required libraries:
   ```bash
   pip install transformers datasets rouge-score sumy nltk matplotlib pandas
   ```
3. Download the `xsum.csv` data file and place it in the correct directory.
4. Run the script or the provided notebook.

---

## ğŸ“‚ Project Structure

---
SmartSumm/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ smartsumm1.py             
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ SmartSumm.pdf           
â”‚   â””â”€â”€ SmartSumm_Per.pdf         
â”œâ”€â”€ data/
â”‚   â””â”€â”€ xsum.csv                 
â”œâ”€â”€ results/
â”‚   â””â”€â”€ summaries.csv             
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ SmartSumm_Comparison.ipynb 
â”œâ”€â”€ requirements.txt              
â””â”€â”€ README.md                   

---
## ğŸ“Š Updated Results (Including FLAN-T5)

| Model     | ROUGE-1 | ROUGE-2 | ROUGE-L |
|-----------|---------|---------|---------|
| BART      | 0.4821  | 0.2541  | 0.4075  |
| FLAN-T5   | 0.3500  | 0.1800  | 0.3000  |
| T5        | 0.1975  | 0.0366  | 0.1425  |
| TextRank  | 0.1633  | 0.0276  | 0.1107  |

> **BART significantly outperforms both T5 and TextRank across all ROUGE metrics, demonstrating the power of transformer-based abstractive summarization on news data.**
## ğŸŒŸ New Features
- Added **FLAN-T5** with prompt engineering for better summaries.
- Automated ROUGE scoring and visualization.
---
## ğŸ› ï¸ How to Run
1. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
2. Download the XSum dataset and place it in `data/xsum.csv`.
3. Run the summarizer:
   ```bash
   python src/smartsumm1.py
   ```
## ğŸ¤ Contribution

This project is open source! If you have suggestions or enhancements, feel free to open a Pull Request or Issue.

---

## ğŸ“¬ Contact

For questions or collaboration:

- Mariam [GitHub](https://github.com/Mariam-abdelfttah)
- Omnia [GitHub](https://github.com/Omnia-adel1)
  
-Mariam Elrafei â€” Lead Developer & Researcher
Worked on model implementation, data preprocessing, and evaluation metrics.

-Omnia Adel â€” Data Engineer & Analyst
Handled dataset preparation, performance visualization, and results analysis.



---

<div align="center">
  <b>Thank you for your interest in the SmartSumm project â­</b>
</div>
